{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for the final output of the test dataset\n",
    "\n",
    "Here we changed something in order to print the results for the test dataset in the correct way. The code is basically the same from main.py, refer to that file for the real implementation for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "from utils.data_loader import ImageDataset\n",
    "from model.cnn import CNN\n",
    "from model.cnn2 import CNN2\n",
    "from model.cnn3 import CNN3\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from utils.performance_measure import precision_recall_f1\n",
    "warnings.filterwarnings('ignore')\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "torch.set_num_threads(22)\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "BATCH_SIZE_TRAIN = 2000\n",
    "BATCH_SIZE_TEST = 2000\n",
    "TRANSFORM = False\n",
    "\n",
    "\"\"\"\n",
    "SETUP\n",
    "\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "classes = [] # Get all the classes for one-hot encoding\n",
    "for filename in os.listdir('../data/annotations'):\n",
    "    filename, _ = os.path.splitext(filename)\n",
    "    classes.append(filename)\n",
    "classes = list(set(classes))\n",
    "\n",
    "\"\"\"\n",
    "COLLATE FUNCTION\n",
    "Input:\n",
    "    - batch: a simple batch from data loader\n",
    "Output: \n",
    "    - zip of samples in order to form a batch which can be used by the standard implementation of the training procedure\n",
    "\"\"\"\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\"\"\"\n",
    "DATA AUGMENTATION\n",
    "    - ColorJitter: random brightness and contrast change\n",
    "    - RandomAdjustSharpness: random change sharpness (not too hardly and with low probability)\n",
    "    - RandomInvert: random invert colors\n",
    "    - RandomRotation: just a small rotation\n",
    "Note: depends on TRANSFORM\n",
    "\"\"\"\n",
    "train_transform = transforms.Compose([\n",
    "                                        transforms.ColorJitter(brightness=.5, contrast=.3),\n",
    "                                        transforms.RandomAdjustSharpness(sharpness_factor=1.1, p=.1),\n",
    "                                        transforms.RandomInvert(p=.1),\n",
    "                                        transforms.RandomRotation(degrees=2)\n",
    "                                        ]) if TRANSFORM else None\n",
    "\n",
    "\"\"\"\n",
    "DATA LOADING\n",
    "    - Load all data with custom ImageDataset class\n",
    "    - Create test-train-dev splits and create the DataLoader objects\n",
    "\"\"\"\n",
    "data = ImageDataset(label_dir='../data/annotations', img_dir='../data/images', classes=classes, transform=train_transform)\n",
    "\n",
    "train_size = int(TRAIN_SIZE*len(data))\n",
    "test_size = int(len(data)-train_size)\n",
    "train_set, test_set = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE_TRAIN, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=BATCH_SIZE_TEST, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 PRECISION: 0.20445800719561363\n",
      "EPOCH 0 RECALL: 0.541637768288763\n",
      "EPOCH 0 F1-SCORE: 0.2841073312350703\n",
      "Epoch 0 Validation loss 0.40095336735248566\n",
      "EPOCH 1 PRECISION: 0.3107196519103894\n",
      "EPOCH 1 RECALL: 0.5120679953327992\n",
      "EPOCH 1 F1-SCORE: 0.38533047381122076\n",
      "Epoch 1 Validation loss 0.36685608327388763\n",
      "EPOCH 2 PRECISION: 0.3290206401997256\n",
      "EPOCH 2 RECALL: 0.5723475119919789\n",
      "EPOCH 2 F1-SCORE: 0.41510309653188887\n",
      "Epoch 2 Validation loss 0.3622354120016098\n",
      "EPOCH 3 PRECISION: 0.3292167621629845\n",
      "EPOCH 3 RECALL: 0.567923097757969\n",
      "EPOCH 3 F1-SCORE: 0.41560185132908795\n",
      "Epoch 3 Validation loss 0.36408497393131256\n",
      "EPOCH 4 PRECISION: 0.32877297591903154\n",
      "EPOCH 4 RECALL: 0.5725582285058626\n",
      "EPOCH 4 F1-SCORE: 0.4157034295662583\n",
      "Epoch 4 Validation loss 0.36419475078582764\n",
      "EPOCH 5 PRECISION: 0.328258782530228\n",
      "EPOCH 5 RECALL: 0.554960365300006\n",
      "EPOCH 5 F1-SCORE: 0.4114663473207939\n",
      "Epoch 5 Validation loss 0.3661970794200897\n",
      "EPOCH 6 PRECISION: 0.32876518097014684\n",
      "EPOCH 6 RECALL: 0.5657663813228753\n",
      "EPOCH 6 F1-SCORE: 0.414710665303045\n",
      "Epoch 6 Validation loss 0.3645068407058716\n",
      "EPOCH 7 PRECISION: 0.3274376377358535\n",
      "EPOCH 7 RECALL: 0.555379270415717\n",
      "EPOCH 7 F1-SCORE: 0.4098097075516618\n",
      "Epoch 7 Validation loss 0.364864781498909\n",
      "TEST PRECISION: 0.34444721415268986\n",
      "TEST RECALL: 0.5144725521816111\n",
      "TEST F1-SCORE 0.41259204345645495\n"
     ]
    }
   ],
   "source": [
    "LR = 0.001\n",
    "N_EPOCHS = 10\n",
    "PATIENCE = 4\n",
    "IS_VERBOSE = False\n",
    "ACTIVATION_TRESHOLD = 0.25\n",
    "WEIGHT_DECAY = 0.2\n",
    "\n",
    "\"\"\"\n",
    "HYPERPARAMETERS AND CONSTANTS\n",
    "    - TRAIN_SIZE: size of the training set\n",
    "    - BATCH_SIZE_TRAIN: size of the batches for training phase\n",
    "    - BATCH_SIZE_TEST: size of the batches for testing phase\n",
    "    - LR: learning rate\n",
    "    - N_EPOCHS: number of epochs to execute\n",
    "    - PATIENCE: the number of previous validation losses smaller than the actual one needed to early stop the training\n",
    "    - IS_VERBOSE: to avoid too much output\n",
    "    - ACTIVATION_TRESHOLD: the threshold for the activation function to consider a class as present\n",
    "    - WEIGHT_DECAY: the weight decay for the regularization in Adam optimizer\n",
    "    - USE_VALIDATION: to use the validation set or not. If false only the test set is used, if true the validation set is used\n",
    "    - TRANSFORM: to use the data augmentation or not\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "MODEL INITIALIZATION\n",
    "    - optimizer: Adam with weight decay as regularization technique\n",
    "    - loss function: binary cross entropy loss\n",
    "\"\"\"\n",
    "model = CNN(dropout=False).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "\"\"\"\n",
    "TRAIN\n",
    "    Notes:\n",
    "    - Uses early stopping if the validation loss does not improve after a certain number of epochs; this depends on PATIENCE.\n",
    "    - Uses the validation set if USE_VALIDATION is true, otherwise the test set is used\n",
    "    - The classes are inferred based on the activation threshold\n",
    "    - Precision, recall and f1 are computed for each epoch and the average is returned\n",
    "\"\"\"\n",
    "pre_valid_losses = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0\n",
    "    valid_losses = []\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "\n",
    "    for batch_num, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, target = torch.stack(data, dim=0), torch.stack(target, dim=0)\n",
    "        outputs = model(data.float())\n",
    "        loss = loss_function(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predictions = outputs.data\n",
    "        predictions = torch.argwhere(predictions > ACTIVATION_TRESHOLD)\n",
    "\n",
    "        target = torch.argwhere(target)\n",
    "        _precision, _recall, _f1 = precision_recall_f1(predictions, target)\n",
    "        precision += _precision\n",
    "        recall += _recall\n",
    "        f1 += _f1\n",
    "\n",
    "        if IS_VERBOSE:\n",
    "            print('Training: Epoch %d - Batch %d/%d: Loss: %.4f' % \n",
    "            (epoch, batch_num, len(train_loader), train_loss / (batch_num + 1)))\n",
    "\n",
    "    print('EPOCH', epoch, 'PRECISION:', (precision / (train_size/BATCH_SIZE_TRAIN)))\n",
    "    print('EPOCH', epoch, 'RECALL:', (recall / (train_size/BATCH_SIZE_TRAIN)))\n",
    "    print('EPOCH', epoch, 'F1-SCORE:', (f1 / (train_size/BATCH_SIZE_TRAIN)))\n",
    "\n",
    "    \"\"\"\n",
    "    EARLY STOPPING\n",
    "    When validation loss is higher than the previous PATIENCE ones it stops.\n",
    "    If there have been PATIENCE or more previous losses smaller than the actual, stop\n",
    "    \"\"\"\n",
    "    model.eval() \n",
    "    for data, target in test_loader:\n",
    "        data, target = torch.stack(data, dim=0), torch.stack(target, dim=0)\n",
    "        output = model(data.float())\n",
    "        loss = loss_function(output, target.float())\n",
    "        valid_losses.append(loss.item())\n",
    "\n",
    "    valid_loss = np.average(valid_losses)\n",
    "    pre_valid_losses.append(valid_loss)\n",
    "\n",
    "    print('Epoch', epoch, 'Validation loss', valid_loss)\n",
    "\n",
    "    j = 0\n",
    "    # Now start checking if it has to stop\n",
    "    if len(pre_valid_losses) >= PATIENCE:\n",
    "        for l in pre_valid_losses:\n",
    "            if l < valid_loss:\n",
    "                j+=1\n",
    "    if(j>=PATIENCE):\n",
    "        break\n",
    "\n",
    "\"\"\"\n",
    "TEST\n",
    "\"\"\"\n",
    "test_loss = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1 = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_num, (data, target) in enumerate(test_loader):\n",
    "        data, target = torch.stack(data, dim=0), torch.stack(target, dim=0)\n",
    "        outputs = model(data.float())\n",
    "        loss = loss_function(outputs, target.float())\n",
    "        test_loss += loss.item()\n",
    "        predictions = outputs.data\n",
    "        predictions = torch.argwhere(predictions > ACTIVATION_TRESHOLD)\n",
    "        target = torch.argwhere(target)\n",
    "\n",
    "        _precision, _recall, _f1 = precision_recall_f1(predictions, target)\n",
    "        precision += _precision\n",
    "        recall += _recall\n",
    "        f1 += _f1\n",
    "\n",
    "        if IS_VERBOSE:\n",
    "            print('Evaluating: Batch %d/%d: Loss: %.4f' % \n",
    "            (batch_num, len(test_loader), test_loss / (batch_num + 1)))\n",
    "    print('TEST PRECISION:', (precision / (test_size/BATCH_SIZE_TEST)))\n",
    "    print('TEST RECALL:', (recall / (test_size/BATCH_SIZE_TEST)))\n",
    "    print('TEST F1-SCORE',  (f1 / (test_size/BATCH_SIZE_TEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.data_loader_test import ImageDatasetTest\n",
    "\n",
    "new_data = ImageDatasetTest(label_dir='../data/test_fake_annotations', img_dir='../data/test_images', classes=classes, transform=train_transform)\n",
    "# shuffle=False, the images are in the righ order so we can get the names after. I manually checked this\n",
    "new_test_loader = torch.utils.data.DataLoader(dataset=new_data, shuffle=False, collate_fn=collate_fn) \n",
    "image_names = new_data.image_names # get image names\n",
    "enc_labels = new_data.enc_labels # get encoded labels\n",
    "e = [i for i in range(0,14)]\n",
    "enc_labels = dict(zip(e, enc_labels))\n",
    "\n",
    "# Get the predictions in the usual way\n",
    "preds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_num, (data, _) in enumerate(new_test_loader,0):\n",
    "        data = torch.stack(data, dim=0)\n",
    "        outputs = model(data.float())\n",
    "        predictions = outputs.data\n",
    "        preds.append(torch.argwhere(predictions > ACTIVATION_TRESHOLD).tolist())\n",
    "\n",
    "# convert encoded to decoded labels\n",
    "for pred in preds:\n",
    "    for sing in pred:\n",
    "        sing[1] = enc_labels[sing[1]]\n",
    "\n",
    "# transform the prediction into one-hot vectors\n",
    "preds_onehot = {}\n",
    "i = 0\n",
    "for p in preds:\n",
    "    str = ''\n",
    "    for label in enc_labels.values():\n",
    "        str += '1 ' if any(label in x for x in p) else '0 '\n",
    "    preds_onehot[image_names[i]] = str\n",
    "    i+=1\n",
    "\n",
    "# write to file\n",
    "with open('final_results_041_2.txt', 'w') as f:\n",
    "    str = 'image_name\\t'\n",
    "    for c in enc_labels.values():\n",
    "        str += c + '\\t'\n",
    "    f.write(str + '\\n')\n",
    "    for key, value in preds_onehot.items():\n",
    "        f.write(key.strip() + '\\t' + value.replace(' ', '\\t').strip() + '\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
